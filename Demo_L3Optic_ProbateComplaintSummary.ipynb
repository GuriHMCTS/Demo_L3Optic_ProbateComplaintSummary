{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# L3 Probate Complaint Summary Demo\n",
        "\n",
        "This is a break down of the notebook Develop/Notebooks/Layer_3/Optic/L3Optic_ProbateComplaintSummary<br/>\n",
        "The Notebook can be found on, <br/>\n",
        "https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary\n"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "210640a7-c124-4cc0-8dc9-811e45727661"
        },
        "id": "u-FY9fcCD7eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "dTcUb8Ok6mz9",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4709d821-6d75-473e-b053-4f987f6f4813"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from datetime import *\n",
        "import datetime\n",
        "import decimal\n",
        "from delta.tables import *\n",
        "from pprint import pprint as pp"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:29.8474323Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:29.995534Z",
              "execution_finish_time": "2022-04-29T12:40:30.1421109Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 2, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {
        "id": "Sakv4Tn06m0B",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "85d8f522-9e0f-4e68-8335-51394d5df35c"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next 4 cells run other Notebooks, importing all the classes defined in them.<br/> \n",
        "The location of those Notebooks is `Develop/Notebooks/Commons/`  (https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/commons_notebooks.png) \n"
      ],
      "metadata": {
        "id": "-lvTP-NX6m0D",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "74f75efa-5531-4b87-9509-b179daf542cf"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run Commons/DataSpecification"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": 4907,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:29.8901583Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:31.6808133Z",
              "execution_finish_time": "2022-04-29T12:40:31.6810459Z"
            },
            "text/plain": "StatementMeta(, 4907, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "id": "_GOGyYWc6m0D",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4816b2a4-1a27-4247-8b23-4b12d1469005"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run Commons/SynapseDatabaseWriter"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": 4907,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:29.9534665Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:32.8399665Z",
              "execution_finish_time": "2022-04-29T12:40:32.8402127Z"
            },
            "text/plain": "StatementMeta(, 4907, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "id": "-LSjdTNt6m0E",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8d139729-a657-49ea-80d6-326e04104d17"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run Commons/SynapseDatabaseReader"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": 4907,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.1339569Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:33.9004913Z",
              "execution_finish_time": "2022-04-29T12:40:33.9007252Z"
            },
            "text/plain": "StatementMeta(, 4907, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "id": "xOHr4aMv6m0E",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6d84cbb5-4044-4220-88a2-81e6c1746fd8"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run Commons/QA_Support"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": 4907,
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.4096079Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:39.3143157Z",
              "execution_finish_time": "2022-04-29T12:40:39.3145772Z"
            },
            "text/plain": "StatementMeta(, 4907, -1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "id": "c4bSd7b86m0F",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "74fcbe6c-820e-464f-b78b-c4732ef945e5"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "Ifd1114g6m0G",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "cd2270e5-60c8-4f2f-8da3-21bd6ef147d8"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the parameters are hard coded into the Notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CurrentExecutionId = 0\n",
        "parametersJSON = json.dumps({\n",
        "    \"LastModifiedDate\": \"2021-02-10\",\n",
        "    \"sourceName\": \"Optic\",\n",
        "    \"processName\": \"L3Optic_ProbateComplaintSummary\",\n",
        "    \"lakeAccountName\": \"mipolybasestagingtest\",\n",
        "    \"lakeContainerName\": \"transformation\",\n",
        "    \"tblLakeFolder\": \"Layer_1/XCutting/Optic\",\n",
        "    \"tblLakeFileNameItem\": \"L1_Optic_tblOpticItem\",\n",
        "    \"tblLakeFileNameItemStep\": \"L1_Optic_tblOpticItemStep\",\n",
        "    \"tblLakeFileNamePayment\": \"L1_Optic_tblOpticPayment\",\n",
        "    \"fctLakeFolder\": \"Layer_3/XCutting/Optic\",\n",
        "    \"fctLakeFileName\": \"L3_Optic_fctProbateComplaintSummary\",\n",
        "    \"fctLakeFileNameOpticComplaintSummary\": \"L3_Optic_fctOpticComplaintSummary\",\n",
        "    \"dwhEnvironment\": \"test\",\n",
        "    \"dwhDatabase\": \"mi_dwh_test\",\n",
        "    \"dwhSchema\": \"L3_Optic\",\n",
        "    \"dwhTableName\": \"fctProbateComplaintSummary\",\n",
        "    \"lakeErrorFileName\": \"L3_Error_tblProbateComplaintSummary\",\n",
        "    \"lakeErrorFolder\": \"Layer_3/Optic/ErrorTable\",\n",
        "    \"lakeErrorTableName\": \"tblProbateComplaintSummary_Error\",\n",
        "    \"expectationSuiteName\": \"L3/Optic\"\n",
        "})\n",
        "\n",
        "print(f'When you use json.dumps the type for the json is {type(parametersJSON)}')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 23,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.4787739Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:39.4111558Z",
              "execution_finish_time": "2022-04-29T12:40:39.5644021Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 23, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When you use json.dumps the type for the json is <class 'str'>"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "id": "p6HbfwqP6m0H",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "33fcb338-c742-46e4-86c1-886ab732aa41"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging variables"
      ],
      "metadata": {
        "id": "QH3KmGIK6m0J",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "65578787-b163-420a-808d-a21673f04ee5"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#These two variables will be used to count\n",
        "RowsRead = 0\n",
        "RowsCopied = 0 "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 24,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.5472533Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:39.6574228Z",
              "execution_finish_time": "2022-04-29T12:40:39.7974952Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 24, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {
        "id": "1yMuQ0my6m0K",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "55276ad4-3511-4b42-b16a-4dcf392b2380"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Populate variables"
      ],
      "metadata": {
        "id": "ixN8YvSk6m0K",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2300f512-61be-4ab6-a5d1-4b66d8c7c1b4"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use the parsed_json dictionary to populate all relevant variables"
      ],
      "metadata": {
        "id": "fY-Sp0R06m0K",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d58c2018-7eac-4adc-867b-991624c1f0e8"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_json = json.loads(parametersJSON) #Turns the json above into a dictionary\n",
        "print(f'Using json.loads turns the json in str type to a type {type(parsed_json)}')\n",
        "\n",
        "# Run parameters\n",
        "LastLoadedDateTime = parsed_json['LastModifiedDate']\n",
        "sourceName = parsed_json['sourceName']\n",
        "processName = parsed_json['processName']\n",
        "\n",
        "# datalake storage details (target)\n",
        "lakeAccountName = parsed_json['lakeAccountName']\n",
        "lakeContainerName = parsed_json['lakeContainerName']\n",
        "\n",
        "# fct (target)\n",
        "fctLakeFolder = parsed_json['fctLakeFolder']\n",
        "fctLakeFileName = parsed_json['fctLakeFileName']\n",
        "fctTableNameOpticComplaintSummary = parsed_json['fctLakeFileNameOpticComplaintSummary']\n",
        "# dwh (target - datawharehouse)\n",
        "dwhEnvironment = parsed_json['dwhEnvironment']\n",
        "dwhDatabase = parsed_json['dwhDatabase']\n",
        "dwhSchema = parsed_json['dwhSchema']\n",
        "dwhTableName = parsed_json['dwhTableName']\n",
        "\n",
        "# QA\n",
        "lakeErrorFileName = parsed_json['lakeErrorFileName']\n",
        "lakeErrorFolder = parsed_json['lakeErrorFolder']\n",
        "lakeErrorTableName = parsed_json['lakeErrorTableName']\n",
        "expectationSuiteName = parsed_json['expectationSuiteName']\n",
        "lakeErrorFilePath = 'abfss://{container}@{storage}.dfs.core.windows.net/{folder}/{file}.parquet'.format(\n",
        "    container=lakeContainerName,\n",
        "    storage=lakeAccountName,\n",
        "    file=lakeErrorFileName,\n",
        "    folder=lakeErrorFolder\n",
        ")\n",
        "\n",
        "print(f\"\"\"\n",
        "LastLoadedDateTime: {LastLoadedDateTime}\n",
        "sourceName: {sourceName} \n",
        "processName: {processName}\"\"\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.6305925Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:39.8899947Z",
              "execution_finish_time": "2022-04-29T12:40:40.0382315Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using json.loads turns the json in str type to a type <class 'dict'>\n\nLastLoadedDateTime: 2021-02-10\nsourceName: Optic \nprocessName: L3Optic_ProbateComplaintSummary"
          ]
        }
      ],
      "execution_count": 48,
      "metadata": {
        "id": "eIDh1Lty6m0L",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "87dcd4e3-9f32-44b3-bc0f-8ecf9903cb5f"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to data lake\n",
        "\n",
        "Connection is established via linked service."
      ],
      "metadata": {
        "id": "BZ0IRlka6m0M",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "16c51040-3fd3-437d-bffb-d173f9f4a467"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the linked service authentication method is set to Managed Identity or Service Principal, the linked service will use the Managed Identity or Service Principal token with the LinkedServiceBasedTokenProvider provider, for more details visit: <br/> \n",
        "https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-secure-credentials-with-tokenlibrary?pivots=programming-language-python"
      ],
      "metadata": {
        "id": "T3Jgdwkx6m0M",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "eb784fd1-63ba-4448-82ef-7d96cbe68c79"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will give an error before the next cell is run, as there is no such configuration yet\n",
        "spark.conf.get(\"spark.storage.synapse.linkedServiceName\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:40:30.7036574Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:40:40.1328455Z",
              "execution_finish_time": "2022-04-29T12:40:40.2826666Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o209.get.\n: java.util.NoSuchElementException: spark.storage.synapse.linkedServiceName\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:2605)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:74)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
          "traceback": [
            "Py4JJavaError: An error occurred while calling o209.get.\n: java.util.NoSuchElementException: spark.storage.synapse.linkedServiceName\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:2605)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:74)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/conf.py\", line 51, in get\n    return self._jconf.get(key)\n",
            "  File \"/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n    answer, self.gateway_client, self.target_id, self.name)\n",
            "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n    return f(*a, **kw)\n",
            "  File \"/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n    format(target_id, \".\", name), value)\n",
            "py4j.protocol.Py4JJavaError: An error occurred while calling o209.get.\n: java.util.NoSuchElementException: spark.storage.synapse.linkedServiceName\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat org.apache.spark.sql.internal.SQLConf$$anonfun$getConfString$2.apply(SQLConf.scala:2605)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:2605)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:74)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
          ]
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linked_service_name = 'LS_mi_persistent_storage' #Azure Blob Storage, see https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/linked_service.png\n",
        "spark.conf.set(\"spark.storage.synapse.linkedServiceName\", linked_service_name)\n",
        "spark.conf.set(\"fs.azure.account.oauth.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.LinkedServiceBasedTokenProvider\") #configuring authentication, see https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/linked_service_authentication.png"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 27,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:20.793334Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:43:20.9333309Z",
              "execution_finish_time": "2022-04-29T12:43:21.0773129Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 27, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "id": "maZMLpK86m0M",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "45930b59-0c90-4213-8b60-f726d104b551"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.conf.get(\"spark.storage.synapse.linkedServiceName\"))\n",
        "print(spark.conf.get(\"fs.azure.account.oauth.provider.type\"))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 28,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:20.8284414Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:43:21.1808757Z",
              "execution_finish_time": "2022-04-29T12:43:21.3579091Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 28, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LS_mi_persistent_storage\ncom.microsoft.azure.synapse.tokenlibrary.LinkedServiceBasedTokenProvider"
          ]
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load schemas"
      ],
      "metadata": {
        "id": "VodLc3zj6m0N",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "4e2ef4ba-8247-46dd-bf55-359d39bb33c4"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the `Commons/DataSpecification` notebook we have the following,\n",
        "\n",
        "- A `DataSpec` is a light wrapper around a Spark schema that also keeps track of table details when provided. It can be loaded from a table DDL or from a JSON schema.\n",
        "Create a spec based on a JSON schema, as created by the `json` function of Spark data types:\n",
        "```python\n",
        "mySpec = DataSpec.fromFile(\n",
        "    DataIO.schemaLakeFilePath(storageAccount, 'path/to/mySchema.sql')\n",
        ")\n",
        "```\n",
        "<br/><br/>\n",
        "- The `DataIO` class includes a number of convenience functions to read and write data from the blob store and to the data lake. \n",
        "This function creates the full path of a schema file: \n",
        "```python\n",
        "mySchemaPath = DataIO.schemaLakeFilePath(storageAccount, filePath)\n",
        "```\n",
        "<br/><br/>\n",
        "- The `DataTransform` class makes it possible to transform a dataframe from one schema to another by renaming, casting fields and narrowing the selection down to the target fields, in the same order as defined in the target schema. You can use the schemas from a spec of a dataframe:\n",
        "```python\n",
        "trf = DataTransform.fromSchemas(sourceSpec.schema, targetSpec.schema)\n",
        "targetDF = trf.transform(sourceDF)\n",
        "\n",
        "trf = DataTransform.fromSchemas(sourceDF.schema, targetDF.schema)\n",
        "targetDF = trf.transform(sourceDF)\n",
        "```"
      ],
      "metadata": {
        "id": "86N4Sz8-6m0N",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "9e76ac71-0776-47cc-8a97-847e2f0f10f8"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fctProbateComplaintSummarySpec = DataSpec.fromFile(DataIO.schemaLakeFilePath(lakeAccountName, 'Layer_3/XCutting/Optic/fctProbateComplaintSummary.sql'))#Accessing the relevant schema, https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/probate_schema_path.png\n",
        "\n",
        "print(f\"\"\"storageAccount = {lakeAccountName}\n",
        "filePath = Layer_3/XCutting/Optic/fctProbateComplaintSummary.sql\n",
        "URI = {DataIO.schemaLakeFilePath(lakeAccountName, 'Layer_3/XCutting/Optic/fctProbateComplaintSummary.sql')}\n",
        "\n",
        "Schema = {fctProbateComplaintSummarySpec.schema}\"\"\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 29,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:20.9205278Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:43:21.4793797Z",
              "execution_finish_time": "2022-04-29T12:43:32.3065365Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 29, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "storageAccount = mipolybasestagingtest\nfilePath = Layer_3/XCutting/Optic/fctProbateComplaintSummary.sql\nURI = abfss://schemas@mipolybasestagingtest.dfs.core.windows.net/Layer_3/XCutting/Optic/fctProbateComplaintSummary.sql\n\nSchema = StructType(List(StructField(DateKey,TimestampType,true),StructField(SubjectLocationKey,DecimalType(10,6),true),StructField(OwningLocationKey,DecimalType(10,6),true),StructField(CustomerInteractionTypeKey,DecimalType(10,6),true),StructField(InteractionReasonTypeKey,DecimalType(10,6),true),StructField(ChannelMethodTypeKey,DecimalType(10,6),true),StructField(SourceKey,DecimalType(10,6),true),StructField(InteractionCustomerTypeKey,DecimalType(10,6),true),StructField(ReceiptByStepCount,DecimalType(6,0),true),StructField(ReceiptsByItemCount,DecimalType(6,0),true),StructField(ConcludedByStepCount,DecimalType(6,0),true),StructField(ConcludedByItemCount,DecimalType(6,0),true),StructField(ConcludedAtFirstContactCount,DecimalType(6,0),true),StructField(ConcludedInTargetByStepCount,DecimalType(6,0),true),StructField(DaysToConcludeCount,DecimalType(9,0),true),StructField(UpheldCount,DecimalType(6,0),true),StructField(PartUpheldCount,DecimalType(6,0),true),StructField(NotUpheldCount,DecimalType(6,0),true),StructField(ReviewCount,DecimalType(6,0),true),StructField(AppealCount,DecimalType(6,0),true),StructField(AmountPaidAmount,DecimalType(12,2),true),StructField(ComplaintHasPaymentCount,DecimalType(6,0),true),StructField(OmbudsmanCaseCompletedCount,DecimalType(6,0),true)))"
          ]
        }
      ],
      "execution_count": 52,
      "metadata": {
        "id": "rK_35qNE6m0N",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "53ed0ba9-19aa-4034-96d9-48d7c2a5dc96"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load sources"
      ],
      "metadata": {
        "id": "SGZUCLgE6m0O",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "b1d592bb-ff1d-44ef-8ff1-e6710988e0b0"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the class DataIO:\n",
        "```python\n",
        "def readReferenceData(filePath, format = 'delta'):\n",
        "        return spark.read.format('delta').load(filePath)\n",
        "```\n",
        "```python\n",
        "def lakeFilePath(container, storageAccount, folder, fileName):\n",
        "        return f'abfss://{container}@{storageAccount}.dfs.core.windows.net/{folder}/{fileName}'\n",
        "```\n",
        "```python\n",
        "def referenceDataLakeFilePath(storageAccount, filePath, container = None):\n",
        "        if container is None:\n",
        "            container = DataIO.CONTAINER_REFERENCE_DATA\n",
        "        return f'abfss://{container}@{storageAccount}.dfs.core.windows.net/{filePath}'\n",
        "```\n",
        "```python\n",
        "REFDATA_SHARED_PREFIX = 'Reporting_Reference'\n",
        "```"
      ],
      "metadata": {
        "id": "jjk3tMSE6m0O",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "0eb9b8a5-88ef-43ce-acf2-cd31e9529e1c"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating data frames \n",
        "fctOpticComplaintSummary = spark.read.format('delta').load(\n",
        "    DataIO.lakeFilePath(lakeContainerName, lakeAccountName, fctLakeFolder, f'{fctTableNameOpticComplaintSummary}.parquet')\n",
        ") #The data source, https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/fctOpticComplaintSummary_data_source.png\n",
        "\n",
        "dimJurisdiction = DataIO.readReferenceData(\n",
        "    DataIO.referenceDataLakeFilePath(lakeAccountName, DataIO.REFDATA_SHARED_PREFIX+'/dimJurisdiction.parquet')\n",
        ") #The data source, https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/dimJurisdiction_data_source.png\n",
        "\n",
        "#Creating views of the df's using the pyspark.sql function createOrReplaceTempView\n",
        "fctOpticComplaintSummary.createOrReplaceTempView('fctOpticComplaintSummary') \n",
        "dimJurisdiction.createOrReplaceTempView('dimJurisdiction') \n",
        "\n",
        "print(f\"\"\"fctOpticComplaintSummary (type = {type(fctOpticComplaintSummary)}):\n",
        "container = {lakeContainerName}, \n",
        "storageAccount = {lakeAccountName},\n",
        "folder = {fctLakeFolder},\n",
        "fileName = {fctTableNameOpticComplaintSummary}.parquet\n",
        "URI = {DataIO.lakeFilePath(lakeContainerName, lakeAccountName, fctLakeFolder, f'{fctTableNameOpticComplaintSummary}.parquet')}\n",
        "fctOpticComplaintSummary Data Frame (total rows = {fctOpticComplaintSummary.count()})\n",
        "\"\"\")\n",
        "fctOpticComplaintSummary.show(n=2, vertical=True)\n",
        "\n",
        "\n",
        "print(f\"\"\"dimJurisdiction (type = {type(dimJurisdiction)}):\n",
        "storageAccount = {lakeAccountName}, \n",
        "filePath = Reporting_Reference/dimJurisdiction.parquet\n",
        "URI = {DataIO.referenceDataLakeFilePath(lakeAccountName, DataIO.REFDATA_SHARED_PREFIX+'/dimJurisdiction.parquet')}\n",
        "dimJurisdiction Data Frame (total rows = {dimJurisdiction.count()})\n",
        "\"\"\")\n",
        "dimJurisdiction.show(n=2)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 30,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:21.610986Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:43:32.4068168Z",
              "execution_finish_time": "2022-04-29T12:44:01.4405247Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 30, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fctOpticComplaintSummary (type = <class 'pyspark.sql.dataframe.DataFrame'>):\ncontainer = transformation, \nstorageAccount = mipolybasestagingtest,\nfolder = Layer_3/XCutting/Optic,\nfileName = L3_Optic_fctOpticComplaintSummary.parquet\nURI = abfss://transformation@mipolybasestagingtest.dfs.core.windows.net/Layer_3/XCutting/Optic/L3_Optic_fctOpticComplaintSummary.parquet\nfctOpticComplaintSummary Data Frame (total rows = 32)\n\n-RECORD 0-------------------------------------------\n DateKey                      | 2022-04-07 00:00:00 \n OwningLocationKey            | 1.000302            \n SubjectLocationKey           | 1.000302            \n CustomerInteractionTypeKey   | 13.000004           \n InteractionReasonTypeKey     | 27.002233           \n ChannelMethodTypeKey         | 17.000006           \n SourceKey                    | 9.000014            \n JurisdictionKey              | 15.000001           \n InteractionCustomerTypeKey   | 33.000002           \n CaseSourceTypeKey            | null                \n ReceiptByStepCount           | 1.000000            \n ReceiptsByItemCount          | 1.000000            \n ConcludedByStepCount         | 0.000000            \n ConcludedByItemCount         | 0.000000            \n ConcludedAtFirstContactCount | 0                   \n ConcludedInTargetByStepCount | 0                   \n DaysToConcludeCount          | 0                   \n UpheldCount                  | 0                   \n PartUpheldCount              | 0                   \n NotUpheldCount               | 0                   \n ReviewCount                  | 0                   \n AppealCount                  | 0                   \n PaidAmount                   | 0.00                \n ComplaintHasPaymentCount     | 0                   \n OmbudsmanCaseCompletedCount  | 0                   \n-RECORD 1-------------------------------------------\n DateKey                      | 2022-03-08 00:00:00 \n OwningLocationKey            | 1.001307            \n SubjectLocationKey           | 1.000048            \n CustomerInteractionTypeKey   | 13.000004           \n InteractionReasonTypeKey     | 27.002233           \n ChannelMethodTypeKey         | 17.000006           \n SourceKey                    | 9.000014            \n JurisdictionKey              | 15.000001           \n InteractionCustomerTypeKey   | 33.000002           \n CaseSourceTypeKey            | null                \n ReceiptByStepCount           | 0.000000            \n ReceiptsByItemCount          | 1.000000            \n ConcludedByStepCount         | 0.000000            \n ConcludedByItemCount         | 1.000000            \n ConcludedAtFirstContactCount | 1                   \n ConcludedInTargetByStepCount | 0                   \n DaysToConcludeCount          | 0                   \n UpheldCount                  | 0                   \n PartUpheldCount              | 0                   \n NotUpheldCount               | 0                   \n ReviewCount                  | 0                   \n AppealCount                  | 0                   \n PaidAmount                   | 0.00                \n ComplaintHasPaymentCount     | 0                   \n OmbudsmanCaseCompletedCount  | 0                   \nonly showing top 2 rows\n\ndimJurisdiction (type = <class 'pyspark.sql.dataframe.DataFrame'>):\nstorageAccount = mipolybasestagingtest, \nfilePath = Reporting_Reference/dimJurisdiction.parquet\nURI = abfss://transformation@mipolybasestagingtest.dfs.core.windows.net/Reporting_Reference/dimJurisdiction.parquet\ndimJurisdiction Data Frame (total rows = 58)\n\n+---------------+----------------+------------------+--------------------+------------------------+----------------------------+\n|JurisdictionKey|JurisdictionName|CafeJurisdictionId|CafeJurisdictionName|JurisdictionCategoryName|CSPCJurisdictionCategoryName|\n+---------------+----------------+------------------+--------------------+------------------------+----------------------------+\n|      15.000056|           Other|              null|               Other|                   Other|                        null|\n|      15.000058|           UTIAC|                -1|      Tribunals - IA|                Tribunal|                    Tribunal|\n+---------------+----------------+------------------+--------------------+------------------------+----------------------------+\nonly showing top 2 rows"
          ]
        }
      ],
      "execution_count": 53,
      "metadata": {
        "id": "P-IyfIU_6m0O",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8597cd99-92af-4a5b-827a-63a027a8a6f4"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform to FCT schema"
      ],
      "metadata": {
        "id": "oRHf8h2Y6m0P",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c47cd0b7-6c78-4961-9e0a-01c754ce301b"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a raw dataframe from a SELECT\n",
        "\n",
        "fctProbateComplaintSummaryRaw = spark.sql(\"\"\"\n",
        "SELECT f.DateKey DateKey\n",
        ", f.OwningLocationKey OwningLocationKey\n",
        ", f.SubjectLocationKey SubjectLocationKey\n",
        ", f.CustomerInteractionTypeKey\n",
        ", f.InteractionReasonTypeKey\n",
        ", f.ChannelMethodTypeKey AS ChannelMethodTypeKey\n",
        ", f.SourceKey SourceKey\n",
        ", f.InteractionCustomerTypeKey AS InteractionCustomerTypeKey\n",
        ", f.ReceiptByStepCount\n",
        ", f.ReceiptsByItemCount\n",
        ", f.ConcludedByStepCount\n",
        ", f.ConcludedByItemCount\n",
        ", f.ConcludedAtFirstContactCount\n",
        ", f.ConcludedInTargetByStepCount\n",
        ", f.DaysToConcludeCount\n",
        ", f.UpheldCount\n",
        ", f.PartUpheldCount\n",
        ", f.NotUpheldCount\n",
        ", f.ReviewCount\n",
        ", f.AppealCount\n",
        ", f.PaidAmount as AmountPaidAmount\n",
        ", f.ComplaintHasPaymentCount\n",
        ", f.OmbudsmanCaseCompletedCount     -- 9.0 DJ\n",
        "FROM fctOpticComplaintSummary f\n",
        "INNER JOIN dimJurisdiction d1\n",
        "ON d1.JurisdictionKey = f.JurisdictionKey\n",
        "WHERE d1.JurisdictionName =  'Probate'\n",
        "\"\"\")\n",
        "\n",
        "#use JurisdictionName =  'Civil Money Claims' to see the pipeline work\n",
        "\n",
        "print(f'fctProbateComplaintSummaryRaw (type = {type(fctProbateComplaintSummaryRaw)}) Schema,')\n",
        "fctProbateComplaintSummaryRaw.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 42,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T13:13:56.057021Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T13:13:56.168251Z",
              "execution_finish_time": "2022-04-29T13:13:56.3186331Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 42, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fctProbateComplaintSummaryRaw (type = <class 'pyspark.sql.dataframe.DataFrame'>) Schema,\nroot\n |-- DateKey: timestamp (nullable = true)\n |-- OwningLocationKey: decimal(10,6) (nullable = true)\n |-- SubjectLocationKey: decimal(10,6) (nullable = true)\n |-- CustomerInteractionTypeKey: decimal(10,6) (nullable = true)\n |-- InteractionReasonTypeKey: decimal(10,6) (nullable = true)\n |-- ChannelMethodTypeKey: decimal(10,6) (nullable = true)\n |-- SourceKey: decimal(10,6) (nullable = true)\n |-- InteractionCustomerTypeKey: decimal(10,6) (nullable = true)\n |-- ReceiptByStepCount: decimal(10,6) (nullable = true)\n |-- ReceiptsByItemCount: decimal(10,6) (nullable = true)\n |-- ConcludedByStepCount: decimal(10,6) (nullable = true)\n |-- ConcludedByItemCount: decimal(10,6) (nullable = true)\n |-- ConcludedAtFirstContactCount: decimal(6,0) (nullable = true)\n |-- ConcludedInTargetByStepCount: decimal(6,0) (nullable = true)\n |-- DaysToConcludeCount: decimal(9,0) (nullable = true)\n |-- UpheldCount: decimal(6,0) (nullable = true)\n |-- PartUpheldCount: decimal(6,0) (nullable = true)\n |-- NotUpheldCount: decimal(6,0) (nullable = true)\n |-- ReviewCount: decimal(6,0) (nullable = true)\n |-- AppealCount: decimal(6,0) (nullable = true)\n |-- AmountPaidAmount: decimal(12,2) (nullable = true)\n |-- ComplaintHasPaymentCount: decimal(6,0) (nullable = true)\n |-- OmbudsmanCaseCompletedCount: decimal(6,0) (nullable = true)"
          ]
        }
      ],
      "execution_count": 65,
      "metadata": {
        "id": "cbYCt-MJ6m0P",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "8ae3597c-2ce5-42b8-9ccd-dc1296fb3bee"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coerce it to the target schema\n",
        "\n",
        "trfProbateComplaintSummary = DataTransform.fromSchemas(fctProbateComplaintSummaryRaw.schema, fctProbateComplaintSummarySpec.schema) #DataTransform class is from the Notebook Commons/DataSpecification\n",
        "\n",
        "print(f\"\"\"2 schemas in fromSchemas,\n",
        "fctProbateComplaintSummaryRaw (type = {type(fctProbateComplaintSummaryRaw)}):\n",
        "{fctProbateComplaintSummaryRaw.schema}\n",
        "\n",
        "fctProbateComplaintSummarySpec (type = {type(fctProbateComplaintSummarySpec)}):\n",
        "{fctProbateComplaintSummarySpec.schema}\n",
        "\"\"\")\n",
        "\n",
        "fctProbateComplaintSummary = trfProbateComplaintSummary.transform(fctProbateComplaintSummaryRaw)\n",
        "\n",
        "print(f\"\"\"fctProbateComplaintSummary (type = {type(fctProbateComplaintSummary)} has {fctProbateComplaintSummary.count()} rows with a Schema,\n",
        "{fctProbateComplaintSummary.schema}\"\"\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 39,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T13:00:18.1546237Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T13:00:18.2613438Z",
              "execution_finish_time": "2022-04-29T13:00:21.086939Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 39, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 schemas in fromSchemas,\nfctProbateComplaintSummaryRaw (type = <class 'pyspark.sql.dataframe.DataFrame'>):\nStructType(List(StructField(DateKey,TimestampType,true),StructField(OwningLocationKey,DecimalType(10,6),true),StructField(SubjectLocationKey,DecimalType(10,6),true),StructField(CustomerInteractionTypeKey,DecimalType(10,6),true),StructField(InteractionReasonTypeKey,DecimalType(10,6),true),StructField(ChannelMethodTypeKey,DecimalType(10,6),true),StructField(SourceKey,DecimalType(10,6),true),StructField(InteractionCustomerTypeKey,DecimalType(10,6),true),StructField(ReceiptByStepCount,DecimalType(10,6),true),StructField(ReceiptsByItemCount,DecimalType(10,6),true),StructField(ConcludedByStepCount,DecimalType(10,6),true),StructField(ConcludedByItemCount,DecimalType(10,6),true),StructField(ConcludedAtFirstContactCount,DecimalType(6,0),true),StructField(ConcludedInTargetByStepCount,DecimalType(6,0),true),StructField(DaysToConcludeCount,DecimalType(9,0),true),StructField(UpheldCount,DecimalType(6,0),true),StructField(PartUpheldCount,DecimalType(6,0),true),StructField(NotUpheldCount,DecimalType(6,0),true),StructField(ReviewCount,DecimalType(6,0),true),StructField(AppealCount,DecimalType(6,0),true),StructField(AmountPaidAmount,DecimalType(12,2),true),StructField(ComplaintHasPaymentCount,DecimalType(6,0),true),StructField(OmbudsmanCaseCompletedCount,DecimalType(6,0),true)))\n\nfctProbateComplaintSummarySpec (type = <class '__main__.DataSpec'>):\nStructType(List(StructField(DateKey,TimestampType,true),StructField(SubjectLocationKey,DecimalType(10,6),true),StructField(OwningLocationKey,DecimalType(10,6),true),StructField(CustomerInteractionTypeKey,DecimalType(10,6),true),StructField(InteractionReasonTypeKey,DecimalType(10,6),true),StructField(ChannelMethodTypeKey,DecimalType(10,6),true),StructField(SourceKey,DecimalType(10,6),true),StructField(InteractionCustomerTypeKey,DecimalType(10,6),true),StructField(ReceiptByStepCount,DecimalType(6,0),true),StructField(ReceiptsByItemCount,DecimalType(6,0),true),StructField(ConcludedByStepCount,DecimalType(6,0),true),StructField(ConcludedByItemCount,DecimalType(6,0),true),StructField(ConcludedAtFirstContactCount,DecimalType(6,0),true),StructField(ConcludedInTargetByStepCount,DecimalType(6,0),true),StructField(DaysToConcludeCount,DecimalType(9,0),true),StructField(UpheldCount,DecimalType(6,0),true),StructField(PartUpheldCount,DecimalType(6,0),true),StructField(NotUpheldCount,DecimalType(6,0),true),StructField(ReviewCount,DecimalType(6,0),true),StructField(AppealCount,DecimalType(6,0),true),StructField(AmountPaidAmount,DecimalType(12,2),true),StructField(ComplaintHasPaymentCount,DecimalType(6,0),true),StructField(OmbudsmanCaseCompletedCount,DecimalType(6,0),true)))\n\nfctProbateComplaintSummary (type = <class 'pyspark.sql.dataframe.DataFrame'> has 0 rows with a Schema,\nStructType(List(StructField(DateKey,TimestampType,true),StructField(SubjectLocationKey,DecimalType(10,6),true),StructField(OwningLocationKey,DecimalType(10,6),true),StructField(CustomerInteractionTypeKey,DecimalType(10,6),true),StructField(InteractionReasonTypeKey,DecimalType(10,6),true),StructField(ChannelMethodTypeKey,DecimalType(10,6),true),StructField(SourceKey,DecimalType(10,6),true),StructField(InteractionCustomerTypeKey,DecimalType(10,6),true),StructField(ReceiptByStepCount,DecimalType(6,0),true),StructField(ReceiptsByItemCount,DecimalType(6,0),true),StructField(ConcludedByStepCount,DecimalType(6,0),true),StructField(ConcludedByItemCount,DecimalType(6,0),true),StructField(ConcludedAtFirstContactCount,DecimalType(6,0),true),StructField(ConcludedInTargetByStepCount,DecimalType(6,0),true),StructField(DaysToConcludeCount,DecimalType(9,0),true),StructField(UpheldCount,DecimalType(6,0),true),StructField(PartUpheldCount,DecimalType(6,0),true),StructField(NotUpheldCount,DecimalType(6,0),true),StructField(ReviewCount,DecimalType(6,0),true),StructField(AppealCount,DecimalType(6,0),true),StructField(AmountPaidAmount,DecimalType(12,2),true),StructField(ComplaintHasPaymentCount,DecimalType(6,0),true),StructField(OmbudsmanCaseCompletedCount,DecimalType(6,0),true)))"
          ]
        }
      ],
      "execution_count": 62,
      "metadata": {
        "id": "WIAi0hVH6m0P",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "ffa690e6-74b9-4845-8dcc-c93b97316e0c"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write to data lake and DWH\n",
        "\n",
        "L3 notebook: overwrite all data in the target data lake file and table."
      ],
      "metadata": {
        "id": "rPNhyNti-sqS",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fd9dae6e-a952-4724-9634-fab7b21c1640"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Counts how many rows will be coppied over when the notebook is run \n",
        "RowsCopied += fctProbateComplaintSummary.count()\n",
        "print(f'RowsCopied = {RowsCopied}')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 33,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:21.6203055Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:44:08.7839166Z",
              "execution_finish_time": "2022-04-29T12:44:12.6525454Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 33, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RowsCopied = 0"
          ]
        }
      ],
      "execution_count": 56,
      "metadata": {
        "id": "yxZ5CbqSth_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fctProbateComplaintSummary.write.format('delta').mode('overwrite').save(\n",
        "    DataIO.lakeFilePath(lakeContainerName, lakeAccountName, fctLakeFolder, f'{fctLakeFileName}.parquet')\n",
        ") #Updating/overwriting the data in https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/fctProbateComplaintSummary_path.png\n",
        "\n",
        "print('URI = ' + DataIO.lakeFilePath(lakeContainerName, lakeAccountName, fctLakeFolder, f'{fctLakeFileName}.parquet'))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 40,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T13:03:24.4423259Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T13:03:24.6244164Z",
              "execution_finish_time": "2022-04-29T13:03:31.469794Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 40, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URI = abfss://transformation@mipolybasestagingtest.dfs.core.windows.net/Layer_3/XCutting/Optic/L3_Optic_fctProbateComplaintSummary.parquet"
          ]
        }
      ],
      "execution_count": 63,
      "metadata": {
        "id": "PO4BhLGz6m0P",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fa76dfec-829a-4bf8-abbd-05dedd7937a6"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SynapseDatabaseWriter(dwhEnvironment, dwhDatabase) #Setting up a writer using the class SynapseDatabaseWriter from the notebook Commons/SynapseDatabaseWriter\n",
        "\n",
        "writer.write(fctProbateComplaintSummary, dwhSchema, dwhTableName) #Writing to the final location, see https://github.com/GuriHMCTS/Demo_L3Optic_ProbateComplaintSummary/blob/main/Images/dwh_location.png\n",
        "\n",
        "print(f\"\"\"In the above cell:\n",
        "env: {dwhEnvironment}\n",
        "synapseDatabaseName: {dwhDatabase}\n",
        "\n",
        "dataframe: {fctProbateComplaintSummary.show(n=2, vertical=True)}\n",
        "databaseSchema: {dwhSchema}\n",
        "databaseTable: {dwhTableName}\"\"\")\n",
        "\n",
        "print(type(writer))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 35,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:21.6233705Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:44:23.3361414Z",
              "execution_finish_time": "2022-04-29T12:44:53.2901416Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 35, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "snapshot_path": "/runNotebookApi/versions/1/run/e10ffc4a-bc6d-4af1-b8e2-b9a88e842a99/snapshot",
              "session_id": "4907",
              "spark_pool": "misparkpool",
              "in_pipeline": false,
              "notebook_name": "WriteToDBPool",
              "run_id": "e10ffc4a-bc6d-4af1-b8e2-b9a88e842a99",
              "error": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n(0 rows)\n\nIn the above cell:\nenv: test\nsynapseDatabaseName: mi_dwh_test\n\ndataframe: None\ndatabaseSchema: L3_Optic\ndatabaseTable: fctProbateComplaintSummary\n<class '__main__.SynapseDatabaseWriter'>"
          ]
        }
      ],
      "execution_count": 58,
      "metadata": {
        "id": "vNtGU6_56m0Q",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "1e2386b4-a45a-4f20-bd76-c677a3983f8b"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct return value"
      ],
      "metadata": {
        "id": "VVvqyRP9tYVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mssparkutils.notebook.exit(json.dumps(returnValue)) #Exits the notebook, will error as returnValue is not defined "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "misparkpool",
              "session_id": 4907,
              "statement_id": 36,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-04-29T12:43:21.6249187Z",
              "session_start_time": null,
              "execution_start_time": "2022-04-29T12:44:53.3929492Z",
              "execution_finish_time": "2022-04-29T12:44:53.5382711Z"
            },
            "text/plain": "StatementMeta(misparkpool, 4907, 36, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'returnValue' is not defined",
          "traceback": [
            "NameError: name 'returnValue' is not defined",
            "Traceback (most recent call last):\n",
            "NameError: name 'returnValue' is not defined\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {
        "id": "YwF0H-Tx6m0Q",
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "2b6d20dc-54de-4ea7-802e-b85fc8c45f58"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": "Break down of the notebook Develop/Notebooks/Layer_3/Optic/L3Optic_ProbateComplaintSummary",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}